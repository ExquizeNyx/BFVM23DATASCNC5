{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Assignment week 01\n",
    "\n",
    "Study the Tutorial tutorial_cluster_scanpy_object and the tutorial_Clustering_Methods\n",
    "\n",
    "Write a brief summary about the following:\n",
    "\n",
    "-\t1. What are common preprocessing steps? Explain for each step why and when you should execute this step and when not.\n",
    "-\t2. What visualization methods are used in the cluster methods tutorial? Explain why the selected method is the most appropriate method for the visualization. Bonus points: do this as well for the scanpy tutorial.\n",
    "-\t3. What performance/evaluation metrics are in the cluster methods tutorial? Explain why the used methods are the most appropriate method for the evaluation.\n",
    "\n",
    "\n",
    "Bonus:\n",
    "You practice the steps yourself with the breast_cancer dataset (clustering_data.csv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preprocessing steps\n",
    "\n",
    "__Inspecting data__:\n",
    "One should understand the content/context of the data and the quality of the data in order to interpret the results. Get an idea about the meaning of variables, format and units <br>\n",
    "- __Inspect Data types__\n",
    "    - Knowing the datatype is important to determine which type of statistical model or machine learning method should be used. <br>\n",
    "- __Amount of features/observations__\n",
    "    - Know the range of data (does it differ per feature)\n",
    "- __Check for missing data__:\n",
    "    - Exclude missing data in the descriptive analysis\n",
    "    - fill missing values with a value\n",
    "    - Imputation\n",
    "    - Filling with sense: he choice depends on furhter processing\n",
    "- __Check if the data is balanced__\n",
    "- __Check for outliers__\n",
    "- __Explore data distribution__:\n",
    "    - Statistically/graphically\n",
    "- __Cleaning data__\n",
    "    - Which data can be used and which is not needed for analysis/prediction\n",
    "- __Normalization__\n",
    "    - With normalization the goal is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.\n",
    "        - Not every dataset needs normalization: only when features have different ranges\n",
    "- __Data transformation/scaling__:\n",
    "    - If the data is not normally distributed the data could be transformed to make it normal. F.e. log transformation to reduce the skew of the data. The skewness can only be used if the 'samples' are the same (homogeneity). Log transformations should only be used on highly skewed data.\n",
    "    - In machine learning scaling of features is often necessary\n",
    "    - If the data contains many outliers, scaling using the mean and variance is likely to not work well.(Solution: robustscale)\n",
    "- __Reshape, subset the data or combine with other sources__\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Clustering methods tutorial\n",
    "Visualization methods used in the clustering methods tutorial are:\n",
    "- Histogram:\n",
    "    - Gives an approximate representation of the ditribution of numerical data. It summarize the continuous data that are measured on an interval scale. It illustrates the major features of the distribution of the data.\n",
    "- Pairplots:\n",
    "    - Pairplots give a good visualization of pairwise distributiions and are usefull to investigate relations between factors/features\n",
    "    - Also good to check if certain transformations and/or scaling of features worked.\n",
    "- Dendrogram:\n",
    "    - Used for plotting hierachical clustering. In hierarchical clustering, it illustrates the arrangement of the clusters produced by the corresponding analyses (hierarchial relationship between objects) in a tree(it's informative) to work out the best way to allocate objects to a cluster.\n",
    "    - With HAC there isno need to specify the number of clusters (determines themselves). Also, it can handle arbitrary shapes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bonus: Tutorial cluster scanpy object\n",
    "Visualization methods used in the tutorial scanpy object are:\n",
    "- Violin plot:\n",
    "    - Combines the density and boxplot together in one plot. The advantage of a violinplot is that it can show nuances in the distribution compared to a boxplot. (Outliers are however harder to visualize). This type of plot is highly informative plotting the distribution, outliers, central tendency and variation.\n",
    "- Scatterplot:\n",
    "    - Able to plot possible relations between features. Helps in this case to identify low vs good quality data and helps to determine thresholds/criteria to filter by.\n",
    "- Scree plot:\n",
    "    - Shows how much of the variation in the data is captured by each principal component and can be used to determine how many principal components are necessary to explain the majority of the variance\n",
    "- PCA plot:\n",
    "    - Shows clusters of samples based on their similarity. PCA reduces the the overwhelming number of dimensions by constructing principal components without discarding any sample or variables. The principal components describe variation and account for the influences of the original variables, these influences can produce the differences/similarities among the clusters formed.\n",
    "- UMAP-plot:\n",
    "    - UMAP is an on-linear dimensionality reduction method that visualizes clustering results of high dimensional data. In this example, the clustering allows us to gain insights into the underlying cell populations and identify potential markers that can be used for downstream analyses.\n",
    "    - UMAP is similar to t-SNE, (which is computationally expensive) but has higher processing speed and is very effective for visualizing clusters or groups of data points and there relative proximities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Clustering methods tutorial\n",
    "- Elbow method:\n",
    "    - Evaluating cluster performance based on the inertia. It helps in determining the right amount of clusters to use for the model.\n",
    "- ROC-AUC scores (prediction score):\n",
    "    - Shows how efficient the model is. (The higher the AUC score, the better the models performance.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
